# Chapter10 期中大作业

> 王洲烽，边圣陶

> &emsp;&emsp;本章节对前三章的内容掌握程度进行一个小小的测试，包括一些面向企业的面试题，和基础的实战编程题。也算作最后的收尾工作，以实战作为我们课程的结束。

## 10. 1 面试题

### 10.1.1 hive外部表和内部表的区别

内部表的数据由hive管理，且存储在hive.metastore.warehouse.dir配置下的路径中；外部表的数据由HDFS存储，路径可以自己指定。

删除表时，内部表会把元数据及真实数据删除；外部表不删除真实数据。

### 10.1.2 简述对Hive桶的理解？

桶是对数据某个字段进行哈希取值，然后放到不同文件中存储。 数据加载到桶表时，会对字段取hash值，然后与桶的数量取模。把数据放到对应的文件中。物理上，每个桶就是表(或分区）目录里的一个文件，一个作业产生的桶(输出文件)和reduce任务个数相同。

### 10.1.3 HBase和Hive的区别？

|          | HBase                                              | Hive             |
| :------- | :------------------------------------------------- | ---------------- |
| 类型     | 列式数据库                                         | 数据仓库         |
| 内部机制 | 数据库引擎                                         | MapReduce        |
| 增删改查 | 都支持                                             | 只支持导入和查询 |
| Schema   | 只需要预先定义列族，不需要具体到列，列可以动态修改 | 需要预先定义表格 |
| 应用场景 | 实时                                               | 离线处理         |
| 特点     | 以K-V形式存储                                      | 类SQL            |

Hive和HBase是两种基于Hadoop的不同技术--Hive是一种类SQL的引擎，并且运行MapReduce任务，HBase是一种在Hadoop之上的NoSQL 的Key/vale数据库。当然，这两种工具是可以同时使用的。就像用Google来搜索，用Facebook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到HBase，设置再从HBase写回Hive

### 10.1.4 简述Spark宽窄依赖

窄依赖是指父RDD的每个分区只被子RDD的一个分区所使用，**子RDD分区通常对应常数个父RDD分区**(O(1)，与数据规模无关)

相应的，宽依赖是指父RDD的每个分区都可能被多个子RDD分区所使用，**子RDD分区通常对应所有的父RDD分区**(O(n)，与数据规模有关)

<img src="https://uploadfiles.nowcoder.com/files/20221019/234314825_1666189198264/1666187439425-907574ff-77f9-4edd-a991-a531695173ae.png" alt="img" style="zoom:80%;" />

### 10.1.5 Hadoop和Spark的相同点和不同点

**相同点：**

1）Hadoop和Spark都是并行计算，两者都是用MR模型进行计算。

2）都提供了灾难恢复

- Hadoop将每次处理后的数据写入磁盘中，对应对系统错误具有天生优势。
- Spark的数据对象存储在弹性分布式数据集(RDD)中。这些数据对象既可放在内存，也可以放在磁盘，所以RDD也提供完整的灾难恢复功能。

**不同点：**

1）Hadoop将中间结果存放在HDFS中，每次MR都需要刷写-调用，而Spark中间结果存放优先存放在内存中，内存不够再存放在磁盘中，不放入HDFS，避免了大量的IO和刷写读取操作；

2）Hadoop底层使用MapReduce计算架构，只有map和reduce两种操作，表达能力比较欠缺，而且在MR过程中会重复的读写HDFS，造成大量的磁盘IO读写操作，所以适合高时延环境下批处理计算的应用；Spark是基于内存的分布式计算架构，提供更加丰富的数据集操作类型，主要分成转化操作和行动操作，包括map、reduce、filter、flatmap、groupbykey、reducebykey、union和join等，数据分析更加快速，所以适合低时延环境下计算的应用；

3）Spark与Hadoop最大的区别在于迭代式计算模型。基于MapReduce框架的Hadoop主要分为map和reduce两个阶段，所以在一个job里面能做的处理很有限，对于复杂的计算，需要使用多次MR；Spark计算模型是基于内存的迭代式计算模型，根据用户编写的RDD算子和程序，在调度时根据宽窄依赖可以生成多个Stage，根据action算子生成多个Job。所以Spark相较于MapReduce，计算模型更加灵活，可以提供更强大的功能。

4）由于Spark基于内存进行计算，在面对大量数据且没有进行调优的情况下，可能会出现比如OOM内存溢出等情况，导致spark程序可能无法运行起来，而MapReduce虽然运行缓慢，但是至少可以慢慢运行完。

5）Hadoop适合处理静态数据，对于迭代式流式数据的处理能力差；Spark通过在内存中缓存处理的数据，提高了处理流式数据和迭代式数据的性能。

### 10.1.6 Spark为什么比MapReduce块？

1）基于内存计算，减少低效的磁盘交互；

2）高效的调度算法，基于DAG；

3）容错机制Linage，精华部分就是DAG和Lingae

### 10.1.7 说说你对Hadoop生态的认识

Hadoop生态主要分为三大类型，并以此展开来说（开放式）

1）分布式系统：HDFS，HBase

2）分布式计算引擎：Spark，MapReduce

3）周边工具：如zookeeper，pig，hive，oozie，sqoop，ranger，kafka等

## 10.2 实战

### 10.2.1 xxxxx





> 看到这里的小伙伴们，我们的课程终于结束啦，给坚持这么久的自己点个赞鼓鼓掌，希望你能永远保持开源学习的动力，这也是我们的初衷。

# Chapter6 Hive

> 王嘉鹏，shenhao

## 6.1 数据仓库

> ps：到了数据仓库啦，崭新的饱满的和知识相濡以沫的一天，又开始啦！！！！

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.1.0.png)

### 6.1.1 为什么要有数据仓库

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.1.1.png)

&emsp;&emsp;数据的作用有两个：操作型记录的保存和分析型决策的制定。
- 操作型记录的保存通常不必维护历史数据，只需修改数据以反映最新的状态；
- 分析型决策需要保存历史的数据，从而可以更精确的来评估现有状况进行决策。

&emsp;&emsp;基于后者分析型决策的优化，需要高性能地完成用户的查询，因此引出了数据仓库的概念。

### 6.1.2 数据仓库的主要特征
![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.1.2-1.png)

&emsp;&emsp;数据仓库的主要特征是：**主题性**、**集成性**、**非易失性**、**时变性**的数据集合，用于支撑管理决策。

1. 主题性  
    &emsp;&emsp;各个业务系统的数据可能是相互分离的，但数据仓库则是**面向主题的**。数据仓库将不同的业务进行归类并分析，将数据抽象为主题，用于对应某一分析领域所涉及的分析对象。  
    &emsp;&emsp;而操作型记录（即传统数据）对数据的划分并不适用于决策分析。在数据仓库中，基于主题的数据被划分为各自独立的领域，每个领域有各自的逻辑内涵但互不交叉，在抽象层次上对数据进行完整的、一致的和准确的描述。  
    &emsp;&emsp;以零售业务的过程为例：将多个零售业务数据（杂货、冷冻食品、生活用品、肉类等），依据业务主题进行数据划分，可创建一个具有订单、库存和销售等多个业务领域的零售业务数仓。  
    ![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.1.2-2.png)

2. 集成性  
    &emsp;&emsp;确定主题之后，就需要获取与主题相关的数据。这些数据会分布在不同的业务过程中，因此在数据进入数仓之前，需要对这些数据的口径进行统一。  
    &emsp;&emsp;口径统一是指，统一数据来源中的歧义、单位、字长等元素，并进行总和计算，来聚合成新的数据。  
    &emsp;&emsp;以上述零售业务过程中的订单主题为例，对于订单主题，通常会包括三个业务过程：订单、发货和发票。这些过程会产生一些新的指标，如：销售额、发票收入等。  
   ![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.1.2-3.png)

3. 非易失性  
    &emsp;&emsp;数据仓库的目的是分析数据中的规律，因此，添加到数据仓库中的数据，需要保证其稳定，不会轻易丢失和改变。  
    &emsp;&emsp;这里，与传统操作型数据库的区别在于：操作型数据库主要服务于日常的业务操作，产生的数据会实时更新到数据库中，以便业务应用能够迅速获得当前最新数据，不至于影响正常的业务运作。而数据仓库通常是保存历史业务数据，根据业务需要每隔一段时间将一批新的数据导入数据仓库。  

4. 时变性  
    &emsp;&emsp;数据仓库是根据业务需要来建立的，代表了一个业务过程。因此数据仓库分析的结果只能反映过去的业务情况，当业务变化后，数据仓库需要跟随业务的变化而改变，以适应分析决策的需要。  

## 6.2 数仓建模

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.2.png)

&emsp;&emsp;所有的数仓建模都围绕着两个目的：  
1. 查询机制：提供高效的查询性能；  
2. 业务过程：确保用户更方便地理解数据。

&emsp;&emsp;基于上述两个目的，数仓建模主要提供两种方法：**维度建模**和**ER模型**。

### 6.2.1 维度建模和ER模型的对比

- 维度建模从**分析决策的需求**出发构建模型，为分析需求服务。重点关注用户如何更快速地完成需求分析，同时支持复杂查询。
- ER模型建设数仓模型的出发点是**整合数据**，将各个系统中的数据按主题，进行相似性组合和合并，并对数据进行一致性处理，为处理分析决策服务，却不能直接用于分析决策。

&emsp;&emsp;下面，我们以大学教育需求业务为例，来简单了解一下维度建模的数仓设计过程。

### 6.2.2 示例：大学教育数仓建模

&emsp;&emsp;假设大学现在有一个这样的需求：该大学希望了解学生在学校经历的各个方面，按照每学期课程和相关研究结果，分析学生们对什么方面感兴趣以及工作职业的可能方向。

&emsp;&emsp;在维度模型时，通常的设计流程有4个步骤，分别是：  
1. **选择业务过程**：业务过程通常用于表示业务执行的活动，如：学生选课、购买商品等；  
2. **声明粒度**：粒度在数仓中是用于描述每行所想表达的含义，通常根据粒度来确定需要建立的**事实表**。通过事实表来**跟踪记录事件的发生**。事实表通常表示为“谁、在什么时间、做了什么事”。  
3. **确定维度**：将事实表进行拆分，拆分的数据作为维度存放。  
4. **确定事实**：按照拆分的维，对数据进行重新聚合生成新的明细表。  

&emsp;&emsp;根据学生的行为情况，对于大学教育业务可以分为4个核心过程：**学生选课**、**课程注册**、**设施使用**和**学生考勤**。接下来分别对这些业务进行简要说明：

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.2.2-1.png)

1. 学生选课  
&emsp;&emsp;学生选课的过程可以看作是一个漏斗，从最初的查询课程、提交申请、完成选课、选课更改。希望按照每个阶段的不同特点来分析学生的情况。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.2.2-2.png)

2. 课程注册  
&emsp;&emsp;用**事实表**来跟踪学生课程注册的情况，事实表的粒度可以将每个学生每学期的注册课程为一行。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.2.2-3.png)

3. 设备使用  
&emsp;&emsp;大学也会对教学设备进行投资决策，因此也需要了解每个学期中每天每个小时哪个设备被用于什么目的，统计的指标可以是：哪个教学设备使用率最高？教学设备的平均使用率是多少？周五时由于多数人不想来上课是否会导致教学设备使用率下降？

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.2.2-4.png)

4. 学生考勤  
&emsp;&emsp;针对学生考勤的需求，需要去了解本学期中哪门课程的出勤率最低？哪个学生参加哪几门课程？以及哪个老师的课最受学生欢迎等等需求。考勤的粒度可以将每天上课的学生为一行。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.2.2-5.png)

&emsp;&emsp;通过以上几个场景的示例，我们可以大致了解数仓的作用，以及维度建模的基本流程。

## 6.3 Hive基本概念
![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.3.png)

### 6.3.1 概述

&emsp;&emsp;**Hive是建立在Hadoop之上的一种数仓工具**。该工具的功能是将**结构化**、**半结构化**的数据文件映射为一张**数据库表**，基于数据库表，提供了一种类似`SQL`的查询模型（`HQL`），用于访问和分析存储在`Hadoop`文件中的大型数据集。  
&emsp;&emsp;`Hive`本身并不具备存储功能，其核心是将`HQL`转换为`MapReduce`程序，然后将程序提交到`Hadoop`集群中执行。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.3.1_1.png)

### 6.3.2 产生背景

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.3.1_2.png)

&emsp;&emsp;`Hive`的产生背景主要有两个：  

- **使用成本高**：使用`MapReduce`直接处理数据时，需要掌握`Java`等编程语言，学习成本较高，而且使用`MapReduce`不容易实现复杂查询；
- **建立分析型数仓的需求**：`Hive`支持类`SQL`的查询以及支持自定义函数，可以作为数据仓库的工具。

&emsp;&emsp;`Hive`利用`HDFS`存储数据，使用`MapReduce`查询分析数据。将`SQL`转换为`MapReduce`程序，从而完成对数据的分析决策。

> ps：看完了Hive产生的背景，一定很好奇这东西的内部构造是啥吧，小伙伴们，请跟我来
> 坚持学习，沉迷学习，忘我学习，冲冲冲！！！

<center><img src="https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.3.2_emoji.png" style="zoom:80%;" /></center>

### 6.3.3 模拟实现Hive

&emsp;&emsp;这里通过一个简单的需求，来帮助我们更好地理解`Hive`的原理。

- **需求**：在`HDFS`文件系统上有一个文件，其内容如下：

```
1,jingjing,26,hangzhou
2,wenrui,26,beijing
3,dapeng,26,beijing
4,tony,15,hebei
```

&emsp;&emsp;需要根据上述文本内容来设计`Hive`数仓，通过这个数仓，实现用户通过编写`SQL`语句，来处理位于`HDFS`文件系统上的结构化数据，从而统计**来自北京**的**年龄大于20**的人数。

- **分析**：写`SQL`的前提是对表进行操作，而不能是针对文件。那么需要记录文件和表之间的对应关系，关系示意图如下：

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.3.3_2.png)

&emsp;&emsp;要实现上图所示的文件和表的对应关系，关键在于**实现表和文件的映射**，那么需要记录的信息包括：  
- 表是对应于哪个文件的，即表的位置信息；
- 表的列是对应文件的哪一个字段，即字段的位置信息；
- 文件字段之间的分隔符是什么，即内容读取时的分隔操作；

&emsp;&emsp;完成了表和文件的映射后，`Hive`需要对用户编写的`SQL`语句进行语法校验，并且根据记录的元数据信息对`SQL`进行解析，制定执行计划，并将执行计划转化为`MapReduce`程序来执行，最终将执行的结果封装返回给用户。  
&emsp;&emsp;接下来，在`Hive`的核心概念中，我们进一步了解一下表和文件的映射信息。

## 6.4 核心概念

### 6.4.1 元数据

- **metadata**  
&emsp;&emsp;上面所介绍的`Hive`表和文件的映射信息，被称为**元数据**。元数据表示**描述数据的数据**，对于`Hive`来说，元数据就是用来描述`HDFS`文件和表的各种对应关系（位置关系、顺序关系、分隔符）。`Hive`的元数据存储在**关系数据库**中（`Hive`内置的是`Derby`、第三方的是`MySQL`），`HDFS`中存储的是数据。

- **metastore**  
  &emsp;&emsp;`metastore`是**元数据服务**：表示`Hive`操作管理访问元数据的一个服务。用于访问元数据，`metastore`对外提供一个服务地址，使客户端能够连接`Hive`。使用`metastore`的好处如下：
    - 元数据把数据保存在关系数据库中，`Hive`提供元数据服务，通过对外的服务地址，用户能够使用客户端连接Hive，访问并操作元数据；
    - 支持多个客户端的连接，而客户端无需关心数据的存储地址，实现了数据访问层面的解耦操作。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.4.1_1.png)

- `metastore`管理元数据的方式
    1. **内嵌模式**  
        &emsp;&emsp;`metastore`**默认的**部署模式是`metastore`元数据服务和`Hive`服务融合在一起。  
        
    ![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.4.1_2.png)
        
        &emsp;&emsp;在这种模式下，`Hive`服务（即`Hive`驱动本身）、元数据服务`Metastore`，元数据`metadata`（用于存储映射信息）都在同一个`JVM`进程中，元数据存储在内置的**Derby数据库**。当启动`HiveServer`进程时，`Derby`和`metastore`都会启动，不需要额外启动`metastore`服务。但是，一次只能支持一个用户访问，适用于测试场景。

    2. **本地模式**  
        &emsp;&emsp;本地模式与内嵌模式的区别在于：把元数据提取出来，让`metastore`服务与`HiveServer`主进程在同一个`JVM`进程中运行，存储元数据的数据库在单独的进程中运行。元数据一般存储在`MySQL`关系型数据库中。  

    ![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.4.1_3.png)

        &emsp;&emsp;但是，每启动一个`Hive`服务，都会启动一个`metastore`服务。多个人使用时，会启用多个`metastore`服务。
        
    3. **远程模式**  
        &emsp;&emsp;既然可以把元数据存储给提取出来，也可以考虑把`metastore`给提取出来变为单独一个进程。把`metastore`单独进行配置，并在单独的进程中运行，可以保证全局唯一，从而保证数据访问的安全性。（即不随`Hive`的启动而启动）  

    ![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.4.1_4.png)

        &emsp;&emsp;其优点是把`metaStore`服务独立出来，可以安装到远程的服务器集群里，从而解耦`Hive`服务和`metaStore`服务，保证`Hive`的稳定运行。

### 6.4.2 Hive数据模型

&emsp;&emsp;`Hive`的数据都是存储在`HDFS`上的，默认有一个根目录，在`hive-site.xml`中可以进行配置数据的存储路径。`Hive`数据模型的含义是，描述`Hive`组织、管理和操作数据的方式。`Hive`包含如下4种数据模型：

1. **库**  
&emsp;&emsp;`MySQL`中默认数据库是`default`，用户可以创建不同的`database`，在`database`下也可以创建不同的表。`Hive`也可以分为不同的数据（仓）库，和传统数据库保持一致。在传统数仓中创建`database`。默认的数据库也是`default`。`Hive`中的库相当于关系数据库中的命名空间，它的作用是将用户和数据库的表进行隔离。  

2. **表**  
&emsp;&emsp;`Hive`中的表所对应的数据是存储在`HDFS`中，而表相关的元数据是存储在关系数据库中。Hive中的表分为内部表和外部表两种类型，两者的区别在于数据的访问和删除：  
    - 内部表的加载数据和创建表的过程是分开的，在加载数据时，实际数据会被移动到数仓目录中，之后对数据的访问是在数仓目录实现。而外部表加载数据和创建表是同一个过程，对数据的访问是读取`HDFS`中的数据；
    - 内部表删除时，因为数据移动到了数仓目录中，因此删除表时，表中数据和元数据会被同时删除。外部表因为数据还在`HDFS`中，删除表时并不影响数据。

3. **分区**  
&emsp;&emsp;分区是一个优化的手段，目的是**减少全表扫描**，提高查询效率。在`Hive`中存储的方式就是表的主目录文件夹下的子文件夹，子文件夹的名字表示所定义的分区列名字。

4. **分桶**  
&emsp;&emsp;分桶和分区的区别在于：分桶是针对数据文件本身进行拆分，根据表中字段（例如，编号ID）的值，经过`hash`计算规则，将数据文件划分成指定的若干个小文件。分桶后，`HDFS`中的数据文件会变为多个小文件。分桶的优点是**优化join查询**和**方便抽样查询**。

## 6.5 本章小结

&emsp;&emsp;在本章的学习中，主要介绍了数据仓库的主要特征，通过大学教育的数仓建模讲解了维度建模方法；基于建立于`Hadoop`之上的`Hive`工具，主要介绍了`Hive`的基本概念，包括`HQL`执行流程和产生背景，并通过一个小示例，模拟实现`Hive`；还介绍了`Hive`的核心概念，主要有`metadata`、`metastore`、`metastore`管理元数据的方式（内嵌模式、本地模式和远程模式）以及`Hive`的数据模型（库、表、分区和分桶）。

> ps：多用脑，多思考，这一章内容很干，希望大家足够肝。  
> 保护眼睛，保护头发，好好学习，天天向上

<center><img src="https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch6.5.png" style="zoom:80%;" /></center>
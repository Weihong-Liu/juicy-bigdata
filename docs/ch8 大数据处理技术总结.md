# Chapter8 大数据处理技术总结

> 王嘉鹏

## 8.1 大数据技术框架综述

从2015年国家发布《促进大数据发展行动纲要》，到2017年发布《大数据产业发展规划(2016-2020年)》，再到现在（2021年）的国家大数据发展战略。大数据技术无疑处于了时代发展的浪潮之中。

不管你是否从事大数据行业，都有必要了解下大数据的发展。

从第一章到第七章，相信我们已经对**大数据的基本组件**的使用有所了解。实际上，一套大数据的解决方案通常会包含有多个重要的组件，一般来说，大数据框架可以总体上分为**存储引擎**和**计算分析引擎**。存储引擎通常用来存储海量数据，而分析引擎通常用来分析海量数据。

存储引擎，如第三章的HDFS，第四章的HBase。计算分析引擎，如第五章的MapReduce，第六章的Hive，第七章的Spark。下图对常用的存储引擎和分析引擎用到的技术（有些会在以后的课程技术中涉及）做了下汇总。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch8.1.png)

## 8.2 大数据分析引擎的发展简史

下图是笔者根据大数据处理引擎出现时间，总结绘制成了一张简图，在图下方，有详细的文字说明。对过去20年，大数据分析引擎的发展简史和未来方向做下总结。

![](https://gitee.com/shenhao-stu/Big-Data/raw/master/doc_imgs/ch8.2.png)

值得说明的是，该时间标注的是技术出现的时间。这些技术，在生产环境中大量运用，一般要比出现时间晚5-10年左右。

### 萌芽阶段（2003-2008）

20年前（没错，有点久了），随着互联网的发展，数据量在激增，传统架构的存储容量、读写速度、计算效率等越来越无法满足用户的需求。为了解决这些问题，Google提出了三个处理大数据的技术手段，俗称**”三驾马车”**，从此开始进入大数据的萌芽时代。这三驾马车分别是：

- MapReduce：开源分布式并行计算框架

- BigTable：大型的分布式数据库

- GFS：Google的分布式文件系统

2003年、2004年，Google陆续发布了GFS和MapReduce思想细节。

Nutch的创始人Doug Cutting受到启发，用了若干年时间实现了DFS和MapReduce机制，使Nutch性能飙升。

2005年，Hadoop作为Lucene子项目Nutch的一部分正式被引入Apache基金会，随后又从Nutch中剥离，成为一套完整独立的软件，起名为Hadoop，包括HDFS文件存储系统和MapReduce计算引擎。

1. MapReduce

主要目的是：用来解决可扩展性和容错性问题，从而可以通过使用简单的API，专注于大数据处理。

缺点：其抽象层次太低，不便于工作流的编写。

2. FlumeJava

主要目的是：解决MR抽象层次太低的问题，解决单个MR无法满足复杂业务场景的问题，专注自动优化编写的逻辑管道。

### 快速发展阶段（2009-2014）

这个阶段，其实就是大家看到MapReduce的成功，发现分布式处理，还可以这么干，就像打开了新世界的大门。

在这个阶段里，主要出现了Spark、Storm的技术。 

1. **Spark**

主要改进是：

- 内存计算，提高了速度。

- 引入RDD概念，数据可重放，实现一致性

- RDD的抽象概念，使数据流的处理很方便，代码编写简单

缺点是：

- SparkStreaming的实时计算，是伪实时，是mini-batch，不能真正覆盖实时的应用场景。

2. **Storm**

主要优点是：

event级别实时计算，毫秒级低延迟，能满足实时需求

缺点是：

- 较低的一致性保

- 无状态

- 不支持SQL

关于，Storm，比较有趣的是，因为Storm的无状态及较低的一致性保证，Storm的作者，提出了Lambda架构。
即用离线计算+实时计算的架构。

而这个思想，在实时计算和离线计算间，也为后面流批一体的出现埋下了种子。

### 成熟阶段（2015-至今）

技术的发展是一个不断总结的过程，这个阶段，就是总结上面所有组件的优点、抛弃缺点的过程。

1. **DataFlow**

首先是2015年 DataFlow 流批一体论文的发布。

在这之前，大家总是假设，输入数据在某个时间点后会变完整。这个假设是存在问题的，现有的处理无法对于实时的数据会产生延迟。

论文作者们认为当下面临的：一方面是庞大无序的数据，一方面是数据消费者复杂的语义和时间线上的各种需求。

DataFlow抽象出一个具有足够普遍性，灵活性的模型，执行引擎的选择，转换为延迟程度和处理成本之间的选择。（推荐感兴趣的同学，看下这篇[论文](https://apparition957.github.io/2020/01/07/%E3%80%8AThe-Dataflow-Model%E3%80%8B%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91) ）

这也为流批一体的实现，提供了理论基础。

2. **Flink**

现在，很多人都认为，Flink已经成为实时计算的事实标准。Flink 不同于 Spark 的 批处理（batch processing），它着眼于数据的流处理（streaming processing），将输入看做一条stream，把函数应用到 stream 上，再输出。Flink的底层是流式处理，在上层其也基于流式处理构建了 batch，它通过记录流式处理的 start point，以及维护运行过程中的 state 来实现一个窗口的 batch 处理。

Flink的强大实时计算能力，及流批一体的思想等，极有可能会让其成为大数据处理框架的标准。

### 分析引擎发展方向
基于以往分析引擎的迭代，对于分析引擎发展的方向，其实可以总结为下面3个方向：

1、改进编程模型，让我们用更简单的API，写出更复杂的业务处理逻辑。

2、提高处理效率，效率必然是不可缺少的。

3、扩大解决的问题领域，一个处理引擎，能够处理更多的业务场景，意味着更少的维护成本、更少的集群投入、更简单的架构。

## 8.3 尾声

本课程作为大数据导论，从存储引擎和分析引擎两个方面对大数据技术做了介绍。第一章从大数据概述开始，描述了大数据的发展历程及特点。第二章介绍了Hadoop的架构，并通过实验讲解了Linux系统下Hadoop的安装。第三章和第四章描述了存储引擎HDFS和HBase，并通过实验讲解了基本命令操作。第五、六和七章分别描述了分析引擎：MapReduce，Hive和Spark，对数据模型及架构原理进行了讲解，同时也总结了三个分析引擎处理数据时的异同。

我们希望本教程能够给你带给你对大数据处理技术的认识，同时让你在这趟旅途中有所收获。感谢你付出的时间和努力！